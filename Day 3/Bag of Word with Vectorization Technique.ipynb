{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: User defined dataset (Three simple documents containing one sentence each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['It is going to rain today.', 'Today I am not going outside.', 'I am going to watch the season premiere.']\n"
     ]
    }
   ],
   "source": [
    "Document1= 'It is going to rain today.'\n",
    "Document2= 'Today I am not going outside.'\n",
    "Document3= 'I am going to watch the season premiere.'\n",
    "Doc = [Document1,Document2,Document3]\n",
    "print(Doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 : Intializing TFIDFVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3 : Getting feature names of final words that we will use to tag documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 ['it', 'is', 'going', 'to', 'rain', 'today']\n",
      "Document 2 ['today', 'am', 'not', 'going', 'outside']\n",
      "Document 3 ['am', 'going', 'to', 'watch', 'the', 'season', 'premiere']\n"
     ]
    }
   ],
   "source": [
    "analyze = vectorizer.build_analyzer()\n",
    "print('Document 1',analyze(Document1))\n",
    "print('Document 2',analyze(Document2))\n",
    "print('Document 3',analyze(Document3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### we see how each sentence is broken into words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4 : Vectorizing or creating a matrix of all three documents and finding feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document transform [[0.         0.27824521 0.4711101  0.4711101  0.         0.\n",
      "  0.         0.4711101  0.         0.         0.35829137 0.35829137\n",
      "  0.        ]\n",
      " [0.40619178 0.31544415 0.         0.         0.53409337 0.53409337\n",
      "  0.         0.         0.         0.         0.         0.40619178\n",
      "  0.        ]\n",
      " [0.32412354 0.25171084 0.         0.         0.         0.\n",
      "  0.4261835  0.         0.4261835  0.4261835  0.32412354 0.\n",
      "  0.4261835 ]]\n"
     ]
    }
   ],
   "source": [
    "X = vectorizer.fit_transform(Doc)\n",
    "print('Document transform', X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### each word is represented as a number for the machine, as shown above for the three documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['am', 'going', 'is', 'it', 'not', 'outside', 'premiere', 'rain', 'season', 'the', 'to', 'today', 'watch']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The output signifies the important words which add context to 3 sentences. These are the words that are important in all 3 sentences and now we can ask questions of whatever nature you like to the machine"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
